{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /mnt/lustre/scratch/CBRA/projects/CSVS/spanishTest/v2.0/machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cloucera/projects/spanishTest/.env')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv_file_path = Path(find_dotenv())\n",
    "dotenv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cloucera/projects/spanishTest')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path = dotenv_file_path.parent\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/projects/spanishTest/v2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_file_path)\n",
    "data_path = Path(os.environ.get(\"DATA_PATH\"))\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nationality continent\n",
       "HG00096     British  European\n",
       "HG00097     British  European\n",
       "HG00099     British  European\n",
       "HG00100     British  European\n",
       "HG00101     British  European"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_training_path = data_path.joinpath(\"ids_1000g.R\")\n",
    "y_train = pd.read_csv(labels_training_path, header=None, sep=\" \", index_col=0, names=[\"nationality\", \"continent\"])\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/projects/spanishTest/v2/plink.26.Q')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_training_path = data_path.joinpath(\"plink.26.Q\")\n",
    "features_training_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.058456</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.339164</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.110726</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.393844</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.120551</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.243461</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.065509</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.043336</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.287784</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2        3         4         5        6   \\\n",
       "HG00096  0.00001  0.00001  0.00001  0.00001  0.000010  0.000010  0.00001   \n",
       "HG00097  0.00001  0.00001  0.00001  0.00001  0.000010  0.110726  0.00001   \n",
       "HG00099  0.00001  0.00001  0.00001  0.00001  0.000010  0.120551  0.00001   \n",
       "HG00100  0.00001  0.00001  0.00001  0.00001  0.000010  0.000010  0.00001   \n",
       "HG00101  0.00001  0.00001  0.00001  0.00001  0.005575  0.000010  0.00001   \n",
       "\n",
       "              7        8        9   ...        16       17        18  \\\n",
       "HG00096  0.00001  0.00001  0.00001  ...  0.000010  0.00001  0.058456   \n",
       "HG00097  0.00001  0.00001  0.00001  ...  0.000010  0.00001  0.000010   \n",
       "HG00099  0.00001  0.00001  0.00001  ...  0.000010  0.00001  0.000010   \n",
       "HG00100  0.00001  0.00001  0.00001  ...  0.205808  0.00001  0.243461   \n",
       "HG00101  0.00001  0.00001  0.00001  ...  0.000010  0.00001  0.043336   \n",
       "\n",
       "               19       20       21       22        23        24       25  \n",
       "HG00096  0.078883  0.00001  0.00001  0.00001  0.339164  0.000010  0.00001  \n",
       "HG00097  0.000010  0.00001  0.00001  0.00001  0.000010  0.393844  0.00001  \n",
       "HG00099  0.000010  0.00001  0.00001  0.00001  0.358482  0.000010  0.00001  \n",
       "HG00100  0.000010  0.00001  0.00001  0.00001  0.065509  0.000010  0.00001  \n",
       "HG00101  0.000010  0.00001  0.00001  0.00001  0.050009  0.287784  0.00001  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(features_training_path, header=None, sep=\" \")\n",
    "X_train.index = y_train.index\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>nationality</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058456</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.339164</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.110726</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.393844</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00099</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.120551</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.358482</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243461</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.065509</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00101</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043336</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.287784</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>British</td>\n",
       "      <td>European</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index        0        1        2        3         4         5        6  \\\n",
       "0  HG00096  0.00001  0.00001  0.00001  0.00001  0.000010  0.000010  0.00001   \n",
       "1  HG00097  0.00001  0.00001  0.00001  0.00001  0.000010  0.110726  0.00001   \n",
       "2  HG00099  0.00001  0.00001  0.00001  0.00001  0.000010  0.120551  0.00001   \n",
       "3  HG00100  0.00001  0.00001  0.00001  0.00001  0.000010  0.000010  0.00001   \n",
       "4  HG00101  0.00001  0.00001  0.00001  0.00001  0.005575  0.000010  0.00001   \n",
       "\n",
       "         7        8  ...        18        19       20       21       22  \\\n",
       "0  0.00001  0.00001  ...  0.058456  0.078883  0.00001  0.00001  0.00001   \n",
       "1  0.00001  0.00001  ...  0.000010  0.000010  0.00001  0.00001  0.00001   \n",
       "2  0.00001  0.00001  ...  0.000010  0.000010  0.00001  0.00001  0.00001   \n",
       "3  0.00001  0.00001  ...  0.243461  0.000010  0.00001  0.00001  0.00001   \n",
       "4  0.00001  0.00001  ...  0.043336  0.000010  0.00001  0.00001  0.00001   \n",
       "\n",
       "         23        24       25  nationality  continent  \n",
       "0  0.339164  0.000010  0.00001      British   European  \n",
       "1  0.000010  0.393844  0.00001      British   European  \n",
       "2  0.358482  0.000010  0.00001      British   European  \n",
       "3  0.065509  0.000010  0.00001      British   European  \n",
       "4  0.050009  0.287784  0.00001      British   European  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.concat((X_train, y_train), axis=1)\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.columns = [str(col) for col in train_data.columns]\n",
    "train_data.to_feather(data_path.joinpath(\"train_data.feather\"))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "import numpy as np\n",
    "\n",
    "query = y_train.continent == \"European\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.repeat(True, y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f5183a50886a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pca\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/apps/miniconda3/envs/idp3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \"\"\"\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/envs/idp3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    804\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/envs/idp3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter_without_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 863\u001b[0;31m                                                           **opt_args)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/envs/idp3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compute_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/envs/idp3/lib/python3.6/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                       \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                                       \u001b[0mdof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                                       compute_error=compute_error)\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsne = manifold.TSNE(init=\"pca\", n_iter=10**4, metric=\"cosine\")\n",
    "X_t = tsne.fit_transform(X_train.loc[query, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_t, index=X_train.index[query], columns=[\"tsne_0\", \"tsne_1\"])\n",
    "data[\"nationality\"] = y_train.loc[query, \"nationality\"]\n",
    "data[\"continent\"] = y_train.loc[query, \"continent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "sns.set_palette(\"tab20\")\n",
    "sns.scatterplot(\n",
    "    x=\"tsne_0\",\n",
    "    y=\"tsne_1\",\n",
    "    hue=\"nationality\",\n",
    "    data=data,\n",
    "    ax=ax,\n",
    "    s=50\n",
    ")\n",
    "\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = RandomForestClassifier(n_estimators=10**3, n_jobs=-1, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "cross_val_score(clf, X_train, y_train[\"nationality\"].values.ravel(), cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(penalty=\"l2\", max_iter=10**5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = cross_val_predict(clf, X_train.loc[query], y_train.loc[query, \"nationality\"].values.ravel(), cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train.loc[query, \"nationality\"], y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xts, ytr, yts = train_test_split(X_train, y_train.nationality, test_size=0.3, stratify=y_train.nationality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Average CV score on the training set was:0.9146285310055363\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=40, p=2, weights=\"uniform\")),\n",
    "    StackingEstimator(estimator=LogisticRegression(C=5.0, dual=False, penalty=\"l1\")),\n",
    "    RobustScaler(),\n",
    "    ZeroCount(),\n",
    "    PCA(iterated_power=4, svd_solver=\"randomized\"),\n",
    "    LogisticRegression(C=20.0, dual=False, penalty=\"l1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = ExtraTreeClassifier()\n",
    "clf = RidgeClassifierCV()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "classifiers = [\n",
    "    (LogisticRegression(solver='lbfgs', random_state=0), {\n",
    "        'C': np.logspace(-2, 7, 10)\n",
    "    }),\n",
    "    (LinearSVC(random_state=0), {\n",
    "        'C': np.logspace(-2, 7, 10)\n",
    "    }),\n",
    "    (GradientBoostingClassifier(n_estimators=50, random_state=0), {\n",
    "        'learning_rate': np.logspace(-4, 0, 10)\n",
    "    }),\n",
    "    (SVC(random_state=0, gamma='scale'), {\n",
    "        'C': np.logspace(-2, 7, 10)\n",
    "    }),\n",
    "]\n",
    "\n",
    "def get_name(estimator):\n",
    "    name = estimator.__class__.__name__\n",
    "    if name == 'Pipeline':\n",
    "        name = [get_name(est[1]) for est in estimator.steps]\n",
    "        name = ' + '.join(name)\n",
    "    return name\n",
    "\n",
    "names = [get_name(e) for e, g in classifiers]\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for est_idx, (name, (estimator, param_grid)) in enumerate(zip(names, classifiers)):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, iid=False)\n",
    "\n",
    "    cm = ConfusionMatrix(clf, ax=ax)\n",
    "    \n",
    "    with ignore_warnings(category=ConvergenceWarning):\n",
    "        cm.fit(xtr, ytr)\n",
    "\n",
    "    cm.score(xts, yts)\n",
    "    cm.finalize()\n",
    "#     cm.poof()\n",
    "    ax.set_title(\"{} Confusion Matrix\".format(name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autoxgb import OptimizedXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xts, ytr, yts =  train_test_split(\n",
    "    X_train, \n",
    "    y_train[\"nationality\"].values.ravel() == \"Spanish\", \n",
    "    test_size=0.3,\n",
    "    stratify=y_train[\"nationality\"].values.ravel() == \"Spanish\"\n",
    ")\n",
    "xtr.shape, xts.shape, ytr.shape, yts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = OptimizedXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "xgb.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_hat = xgb.predict(xtr)\n",
    "proba_train = xgb.predict_proba(xtr)\n",
    "\n",
    "yts_hat = xgb.predict(xts)\n",
    "proba_test = xgb.predict_proba(xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yts, yts_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.externals.funcsigs import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(proba, y, split):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "    from sklearn.externals.funcsigs import signature\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y, proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    average_precision = average_precision_score(y, proba[:, 1])\n",
    "    precision, recall, _ = precision_recall_curve(y, proba[:, 1])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "    # ROC\n",
    "    lw = 2\n",
    "    axes[0].plot(fpr, tpr, color='darkorange',\n",
    "            lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title(\"ROC\")\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                if 'step' in signature(plt.fill_between).parameters\n",
    "                else {})\n",
    "    axes[1].step(recall, precision, color='b', alpha=0.2,\n",
    "            where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    # P-R curve\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "    plt.suptitle(split)\n",
    "    # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(proba_train, ytr, split=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(proba_test, yts, split=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(*proba_test.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(np.random.rand(*proba_test.shape), yts, split=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for tr in np.linspace(0, 1, 10):\n",
    "    hat = proba_test[:, 1] > tr\n",
    "    print()\n",
    "    print(\"*\"*20)\n",
    "    print(tr)\n",
    "    print(classification_report(yts, hat))\n",
    "    print(pd.crosstab(yts, hat, rownames=['truth'], colnames=['pred'], margins=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = xgb.best_estimator_\n",
    "\n",
    "cross_val_score(clf, X_train, y_train[\"nationality\"].values.ravel() == \"Spanish\", cv=10, n_jobs=-1, scoring=\"average_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Average CV score on the training set was:0.9146285310055363\n",
    "spclf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    StackingEstimator(estimator=KNeighborsClassifier(n_neighbors=40, p=2, weights=\"uniform\")),\n",
    "    StackingEstimator(estimator=LogisticRegression(C=5.0, dual=False, penalty=\"l1\")),\n",
    "    RobustScaler(),\n",
    "    ZeroCount(),\n",
    "    PCA(iterated_power=4, svd_solver=\"randomized\"),\n",
    "    LogisticRegression(C=20.0, dual=False, penalty=\"l1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = y_train[\"nationality\"].values.ravel() == \"Spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(spclf, X_train, y_train_bin, cv=10, n_jobs=-1, scoring=\"average_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spclf.fit(X_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFnCAYAAACRo/HLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFyEIgwAgItQhAEAcJH/B0mkuIRLQbP9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "visualizer = FeatureCorrelation(method='mutual_info-classification', labels=X_train.columns)\n",
    "visualizer.fit(X_train, y_train_bin)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = FeatureCorrelation(labels=X_train.columns)\n",
    "visualizer.fit(X_train, y_train_bin)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = data_path.joinpath(\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC5390</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.247413</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.136553</td>\n",
       "      <td>0.139635</td>\n",
       "      <td>0.015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC5495</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.272710</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.028931</td>\n",
       "      <td>0.048422</td>\n",
       "      <td>0.063321</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>0.139502</td>\n",
       "      <td>0.004261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0071-018-COHO_2</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.234458</td>\n",
       "      <td>0.032649</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.384946</td>\n",
       "      <td>0.015251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC5429</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.263414</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.110378</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.072870</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC5497</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.339984</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.041564</td>\n",
       "      <td>0.246995</td>\n",
       "      <td>0.003436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4         5   \\\n",
       "AC5390           0.000010  0.000010  0.000010  0.247413  0.019974  0.000010   \n",
       "AC5495           0.000010  0.000010  0.000010  0.272710  0.008325  0.000010   \n",
       "0071-018-COHO_2  0.000010  0.022463  0.000010  0.234458  0.032649  0.000010   \n",
       "AC5429           0.000015  0.002578  0.000013  0.263414  0.002529  0.000010   \n",
       "AC5497           0.000010  0.000010  0.000010  0.339984  0.015619  0.117941   \n",
       "\n",
       "                       6         7         8         9   ...        16  \\\n",
       "AC5390           0.015898  0.000010  0.000010  0.003232  ...  0.000010   \n",
       "AC5495           0.000901  0.000010  0.001869  0.006864  ...  0.010808   \n",
       "0071-018-COHO_2  0.014272  0.001247  0.000874  0.015086  ...  0.012613   \n",
       "AC5429           0.000010  0.000010  0.000357  0.004068  ...  0.000010   \n",
       "AC5497           0.004718  0.000010  0.000010  0.000573  ...  0.000010   \n",
       "\n",
       "                       17        18        19        20        21        22  \\\n",
       "AC5390           0.018222  0.056831  0.012823  0.010154  0.000010  0.000010   \n",
       "AC5495           0.028931  0.048422  0.063321  0.000010  0.000010  0.000010   \n",
       "0071-018-COHO_2  0.003407  0.000010  0.001556  0.000010  0.004286  0.002995   \n",
       "AC5429           0.007338  0.110378  0.024996  0.000010  0.000010  0.000010   \n",
       "AC5497           0.020949  0.000010  0.000010  0.000010  0.000010  0.000010   \n",
       "\n",
       "                       23        24        25  \n",
       "AC5390           0.136553  0.139635  0.015021  \n",
       "AC5495           0.035496  0.139502  0.004261  \n",
       "0071-018-COHO_2  0.000010  0.384946  0.015251  \n",
       "AC5429           0.072870  0.187758  0.000010  \n",
       "AC5497           0.041564  0.246995  0.003436  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = []\n",
    "sample_names = []\n",
    "frames = []\n",
    "for fpath in data_path.glob(\"**/*.Q\"):\n",
    "#     print(fpath)\n",
    "    sample_name = fpath.parent.name\n",
    "    group = fpath.parent.parent.name\n",
    "    \n",
    "    df = pd.read_csv(fpath, header=None, sep=\" \")\n",
    "    \n",
    "    if df.shape[0] >= 1:\n",
    "        groups.append(group)\n",
    "        sample_names.append(sample_name)\n",
    "        frames.append(df.iloc[0, :].copy())        \n",
    "\n",
    "test_v2 = pd.concat(frames, axis=1, ignore_index=True).T\n",
    "test_v2.index = sample_names\n",
    "test_v2.drop(\"v2\", axis=0, inplace=True)\n",
    "test_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC5390</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.247413</td>\n",
       "      <td>0.019974</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.136553</td>\n",
       "      <td>0.139635</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>enod_140818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC5495</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.272710</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028931</td>\n",
       "      <td>0.048422</td>\n",
       "      <td>0.063321</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>0.139502</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>enod_140818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0071-018-COHO_2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.234458</td>\n",
       "      <td>0.032649</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.384946</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>enod_140818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC5429</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.263414</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.110378</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.072870</td>\n",
       "      <td>0.187758</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>enod_140818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC5497</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.339984</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.041564</td>\n",
       "      <td>0.246995</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>enod_140818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index         0         1         2         3         4  \\\n",
       "0           AC5390  0.000010  0.000010  0.000010  0.247413  0.019974   \n",
       "1           AC5495  0.000010  0.000010  0.000010  0.272710  0.008325   \n",
       "2  0071-018-COHO_2  0.000010  0.022463  0.000010  0.234458  0.032649   \n",
       "3           AC5429  0.000015  0.002578  0.000013  0.263414  0.002529   \n",
       "4           AC5497  0.000010  0.000010  0.000010  0.339984  0.015619   \n",
       "\n",
       "          5         6         7         8  ...        17        18        19  \\\n",
       "0  0.000010  0.015898  0.000010  0.000010  ...  0.018222  0.056831  0.012823   \n",
       "1  0.000010  0.000901  0.000010  0.001869  ...  0.028931  0.048422  0.063321   \n",
       "2  0.000010  0.014272  0.001247  0.000874  ...  0.003407  0.000010  0.001556   \n",
       "3  0.000010  0.000010  0.000010  0.000357  ...  0.007338  0.110378  0.024996   \n",
       "4  0.117941  0.004718  0.000010  0.000010  ...  0.020949  0.000010  0.000010   \n",
       "\n",
       "         20        21        22        23        24        25        group  \n",
       "0  0.010154  0.000010  0.000010  0.136553  0.139635  0.015021  enod_140818  \n",
       "1  0.000010  0.000010  0.000010  0.035496  0.139502  0.004261  enod_140818  \n",
       "2  0.000010  0.004286  0.002995  0.000010  0.384946  0.015251  enod_140818  \n",
       "3  0.000010  0.000010  0.000010  0.072870  0.187758  0.000010  enod_140818  \n",
       "4  0.000010  0.000010  0.000010  0.041564  0.246995  0.003436  enod_140818  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = test_v2.copy()\n",
    "data_test[\"group\"] = groups[1:]\n",
    "data_test.reset_index(inplace=True)\n",
    "data_test.columns = [str(col) for col in data_test.columns]\n",
    "data_test.to_feather(data_path.joinpath(\"test_data.feather\"))\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results = pd.DataFrame(\n",
    "    {\"is_spanish\": spclf.predict(test_v2), \"proba_spanish\": spclf.predict_proba(test_v2)[:, 1], \"group\": groups},\n",
    "    index=test_v2.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results.groupby(\"is_spanish\").plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results.is_spanish.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results.to_csv(\"test_v2_result_stacking.tsv\", sep=\"\\t\", index=True, index_label=\"sample_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "\n",
    "sns.violinplot(x=\"is_spanish\", y=\"proba_spanish\", data=test_v2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v2_results[~test_v2_results.is_spanish]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_v2 = [\"AC5399\", \"AC5378\", \"AC5390\", \"AC5409\", \"AC5415\", \"AC5532\", \"AC5533\"]\n",
    "\n",
    "test_v2_results.loc[query_v2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "fig, axs = plt.subplots(7, 4, figsize=(22, 6*7), facecolor='w', edgecolor='k')\n",
    "axs = axs.ravel()\n",
    "\n",
    "df = X_train.loc[y_train_bin, :]\n",
    "\n",
    "for i, column in enumerate(df.columns):\n",
    "    isolation_forest = IsolationForest(contamination='auto', behaviour=\"new\")\n",
    "    isolation_forest.fit(df[column].values.reshape(-1,1))\n",
    "\n",
    "    xx = np.linspace(X_train[column].min(), X_train[column].max(), len(X_train)).reshape(-1,1)\n",
    "    anomaly_score = isolation_forest.decision_function(xx)\n",
    "    outlier = isolation_forest.predict(xx)\n",
    "    \n",
    "    axs[i].plot(xx, anomaly_score, label='anomaly score')\n",
    "    axs[i].fill_between(xx.T[0], np.min(anomaly_score), np.max(anomaly_score), \n",
    "                     where=outlier==-1, color='r', \n",
    "                     alpha=.4, label='outlier region')\n",
    "    axs[i].legend()\n",
    "    axs[i].set_title(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "clust = LocalOutlierFactor(n_neighbors=50, contamination='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# scale data first\n",
    "X = StandardScaler().fit_transform(df)\n",
    "\n",
    "db = clust.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_train.nationality.values, y_train.labels, rownames=['truth'], colnames=['pred'], margins=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_path = data_path.parent.joinpath(\"v3\")\n",
    "v3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_projections_path = v3_path.joinpath(\"projections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = []\n",
    "frames = []\n",
    "\n",
    "for fpath in v3_projections_path.glob(\"**/*.Q\"):\n",
    "#     print(fpath)\n",
    "    sample_name = fpath.parent.name\n",
    "    \n",
    "    df = pd.read_csv(fpath, header=None, sep=\" \")\n",
    "    \n",
    "    if df.shape[0] >= 1:\n",
    "        sample_names.append(sample_name)\n",
    "        frames.append(df.iloc[0, :].copy())        \n",
    "    \n",
    "test_v3 = pd.concat(frames, axis=1, ignore_index=True).T\n",
    "test_v3.index = sample_names\n",
    "test_v3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_train_path = v3_path.joinpath(\"plink.3.Q\")\n",
    "v3_metadata_path = v3_path.joinpath(\"samples\")\n",
    "\n",
    "v3_metadata = pd.read_csv(v3_metadata_path, header=None, sep=\"\\t\", names=[\"class\", \"index\"], index_col=1)\n",
    "\n",
    "v3_train = pd.read_csv(v3_train_path, header=None, sep=\" \")\n",
    "v3_train.index = v3_metadata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_tsne = pd.DataFrame(manifold.TSNE(random_state=42).fit_transform(v3_train))\n",
    "v3_tsne.plot(kind=\"scatter\", x=0, y=1, figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_train.plot(style=\".\", subplots=True, figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# fit the model\n",
    "clf = IsolationForest(behaviour='new', max_samples=100,\n",
    "                      random_state=rng, contamination='auto')\n",
    "clf.fit(v3_train)\n",
    "y_pred_train = clf.predict(v3_train)\n",
    "y_pred_test = clf.predict(test_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = v3_metadata.loc[v3_train.index, \"class\"] == \"IBS\"\n",
    "data_filt = v3_train.loc[query, :]\n",
    "\n",
    "v3_tsne = pd.DataFrame(manifold.TSNE(random_state=42).fit_transform(data_filt), columns=[\"tsne0\", \"tsne1\"], index=data_filt.index)\n",
    "# v3_tsne[\"inlier\"] = data_filt\n",
    "v3_tsne[\"class\"] = v3_metadata.loc[query, \"class\"].values\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.scatterplot(x=\"tsne0\", y=\"tsne1\", data=v3_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_train.loc[\"HG01502\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_metadata[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_tsne.inlier.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index.isin(v3_train.index).sum(), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_data = v3_train.copy()\n",
    "v3_data[\"class\"] = v3_metadata.loc[v3_train.index, \"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = v3_data[\"class\"] == \"IBS\"\n",
    "v3_data.loc[query, 1].plot(style=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  v3_data[\"class\"] == \"TSI\"\n",
    "v3_data.loc[query, 1].plot(style=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  v3_data[\"class\"] == \"NAV\"\n",
    "v3_data.loc[query, :].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_train.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lof = X_train.loc[y_train_bin, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=5, novelty=True, contamination=0.01)\n",
    "clf.fit(X_train_lof)\n",
    "pd.Series(clf.predict(X_train.loc[~y_train_bin, :])).value_counts(), sum(y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(clf.predict(test_v2)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.decision_function(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"fun\": spclf.decision_function(X_train), \"nation\": y_train.nationality, \"proba\":spclf.predict_proba(X_train)[:, 1]}, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "sns.boxplot(x=\"nation\", y=\"fun\", data=df1, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"fun\": clf.decision_function(test_v2), \n",
    "        \"proba\": spclf.predict_proba(test_v2)[:, 1],\n",
    "        \"clf\": clf.predict(test_v2),\n",
    "        \"group\": groups\n",
    "    }, \n",
    "    index=test_v2.index)\n",
    "df2[\"nation\"] = \"v2\"\n",
    "df = pd.concat((df1, df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "sns.boxplot(x=\"nation\", y=\"fun\", data=df, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_pred = pd.Series(clf.predict(test_v2), index=test_v2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_v2 = [\"AC5399\", \"AC5378\", \"AC5390\", \"AC5409\", \"AC5415\", \"AC5532\", \"AC5533\"]\n",
    "df2.loc[query_v2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df2.proba > 0.9) & (df2.clf == -1)\n",
    "df2.loc[query, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.groupby(\"nation\").describe().loc[[\"v2\", \"Spanish\"], :]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ((df2.fun < dfs.fun[\"25%\"][\"Spanish\"]) | (df2.fun > dfs.fun[\"75%\"][\"Spanish\"])) & (df2.proba > 0.99)\n",
    "print(sum(query))\n",
    "df2.loc[query, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df2.fun < dfs.fun[\"25%\"][\"Spanish\"])  & (df2.proba > 0.99)\n",
    "print(sum(query))\n",
    "df2.loc[query, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"nation\").describe().loc[[\"v2\", \"Spanish\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
